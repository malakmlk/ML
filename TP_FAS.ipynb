{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_FAS",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDuhYU2rbqkn2L/ADv3n5q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malakmlk/ML/blob/main/TP_FAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnUI6Yq8XZ5i"
      },
      "source": [
        "\n",
        "---\n",
        "# **Saiem MALAK SIQ2**\n",
        "---\n",
        "TP FAS \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAkdTxjy6d4a"
      },
      "source": [
        "\n",
        "# **Chargement des bibliothèques**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bn3kVNOrLLp"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1-MX_BO5AMC"
      },
      "source": [
        "# **Le problem de classification des fleures d'iris:**\n",
        "Comme dataset je vais utiliser le jeu de données [IRIS](https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv). Ce dernier est une base de données regroupant les caractéristiques de trois espèces de fleurs d’Iris, à savoir Setosa, Versicolour et Virginica. Chaque ligne de ce jeu de données est une observation des caractéristiques d’une fleur d’Iris. Ce dataset décrit les espèces d’Iris par quatre propriétés : longueur et largeur de sépales ainsi que longueur et largeur de pétales. La base de données comporte 120 observations ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRPU6sPjAr0U"
      },
      "source": [
        "# **Chargement du jeu de données IRIS**\n",
        "Dans cette partie je vais télecharger le dataset file et le convertir en une structure qu'on peut utiliser dans un programme python.\n",
        "Pour réaliser cela on utiliser la methode **tf.keras.utils.get_file**.\n",
        "je vais Téléchargez le fichier texte CSV et analysez ces valeurs, puis mélangez-le un peu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRr0hSB4rpdu",
        "outputId": "08411d8a-6eb3-4f05-fa09-dec4227e28f8"
      },
      "source": [
        "train_dataset_url=\"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
        "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
        "                                           origin=train_dataset_url)\n",
        "\n",
        "print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Local copy of the dataset file: /root/.keras/datasets/iris_training.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv8Kn1rPBrWt"
      },
      "source": [
        "# **Visualisation du jeu de données**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICU3VhfOB8Zz"
      },
      "source": [
        "En utilisant la commande head -n10,on peut visualiser les 10 premiers lignes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfPWM-eMr9xn",
        "outputId": "34d6b1ed-25bb-4cdb-b73c-f064bce4703c"
      },
      "source": [
        "!head -n10 {train_dataset_fp}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120,4,setosa,versicolor,virginica\n",
            "6.4,2.8,5.6,2.2,2\n",
            "5.0,2.3,3.3,1.0,1\n",
            "4.9,2.5,4.5,1.7,2\n",
            "4.9,3.1,1.5,0.1,0\n",
            "5.7,3.8,1.7,0.3,0\n",
            "4.4,3.2,1.3,0.2,0\n",
            "5.4,3.4,1.5,0.4,0\n",
            "6.9,3.1,5.1,2.3,2\n",
            "6.7,3.1,4.4,1.4,1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJv17BOOB0RT"
      },
      "source": [
        "À partir de cette vue de l'ensemble de données, on peut conclure que:\n",
        "\n",
        "1. La première ligne est un en-tête contenant des informations sur l'ensemble   de données:\n",
        "Il y a 120 exemples au total. Chaque exemple a quatre feautures et l'un des trois noms d'étiquettes possibles.\n",
        "2. Les lignes suivantes sont des enregistrements de données, un exemple par ligne, où:\n",
        "Les quatre premiers champs sont des **features** : ce sont les caractéristiques d'un exemple. Ici, les champs contiennent des nombres flottants représentant les mesures des fleurs.\n",
        "La dernière colonne est le **label** : c'est la valeur que nous voulons prédire. Pour cet ensemble de données, il s'agit d'une valeur entière de 0, 1 ou 2 qui correspond à un nom de fleur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDti92lP4-vy",
        "outputId": "b0e413f0-b5dd-4670-a3d1-5d774b3a546a"
      },
      "source": [
        "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
        "\n",
        "feature_names = column_names[:-1]\n",
        "label_name = column_names[-1]\n",
        "\n",
        "print(\"Features: {}\".format(feature_names))\n",
        "print(\"Label: {}\".format(label_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
            "Label: species\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77OJZrqE6USL"
      },
      "source": [
        "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFYoE4qXCJ1S"
      },
      "source": [
        "# **Création d'un tf.data.dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkBt7ir6LLRG"
      },
      "source": [
        " Afin de pouvoir faire l'analyse de ces données dans une format approprié je vais travailler avec la fonction **tf.data.experimental.make_csv_dataset** qui retourne  un tf.data.Dataset de tf.data.Dataset (features, label) , où features est un dictionnaire: {'feature_name': value}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAjlkubqIz6b"
      },
      "source": [
        "batch_size = 120\n",
        "\n",
        "train_dataset = tf.data.experimental.make_csv_dataset(\n",
        "    train_dataset_fp,\n",
        "    batch_size,\n",
        "    column_names=column_names,\n",
        "    label_name=label_name,\n",
        "    num_epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogrb-UKnJzrA",
        "outputId": "24b50774-827b-498c-ae62-a486d2d6c7b0"
      },
      "source": [
        "features, labels = next(iter(train_dataset))\n",
        "\n",
        "print(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('sepal_length', <tf.Tensor: shape=(120,), dtype=float32, numpy=\n",
            "array([4.6, 5.6, 5.8, 6.8, 4.6, 4.9, 7.2, 5.4, 6. , 6.4, 5. , 5.8, 5.2,\n",
            "       5. , 6.1, 5.9, 6.7, 6.8, 6.4, 7.2, 5.5, 6.7, 7. , 4.9, 5.5, 7.7,\n",
            "       6.3, 7.2, 5.4, 5.2, 4.9, 6. , 6.8, 6.3, 5.1, 6.3, 7.9, 4.8, 6.4,\n",
            "       6.3, 4.7, 5. , 5.4, 5.8, 7.7, 7.7, 6.5, 5. , 5. , 4.4, 5.7, 6. ,\n",
            "       6.1, 5.8, 6.4, 6.5, 6.3, 6.5, 4.9, 4.7, 6.6, 5.1, 6.9, 5.8, 6.7,\n",
            "       6.5, 4.8, 5. , 6.2, 5. , 4.6, 4.6, 5.8, 5. , 7.7, 5.1, 6.1, 5.7,\n",
            "       5.7, 6.9, 7.6, 6.4, 4.8, 4.8, 4.5, 6.2, 7.3, 5.7, 4.4, 4.4, 6.6,\n",
            "       4.9, 6.7, 5.7, 5.1, 6.1, 5.3, 6.9, 6.5, 6.7, 5.2, 5.4, 5.1, 5.7,\n",
            "       6. , 4.9, 6.1, 5.5, 6.3, 5.6, 5.4, 5.9, 6.4, 6.2, 5. , 5.6, 5. ,\n",
            "       5.5, 5.1, 7.4], dtype=float32)>), ('sepal_width', <tf.Tensor: shape=(120,), dtype=float32, numpy=\n",
            "array([3.1, 2.9, 2.8, 2.8, 3.4, 3.1, 3.6, 3.4, 2.9, 3.2, 2.3, 2.6, 3.4,\n",
            "       3.5, 2.8, 3. , 3.1, 3. , 3.2, 3. , 2.4, 3. , 3.2, 2.5, 3.5, 2.8,\n",
            "       2.7, 3.2, 3.9, 2.7, 3.1, 2.7, 3.2, 2.3, 3.8, 3.3, 3.8, 3. , 2.8,\n",
            "       2.5, 3.2, 3.3, 3. , 2.7, 3. , 3.8, 3. , 3.4, 3.5, 2.9, 3.8, 3. ,\n",
            "       2.6, 2.7, 3.1, 3. , 3.4, 3.2, 3. , 3.2, 3. , 2.5, 3.1, 2.7, 3.1,\n",
            "       3. , 3. , 3.2, 3.4, 2. , 3.6, 3.2, 4. , 3.4, 2.6, 3.7, 3. , 4.4,\n",
            "       2.8, 3.1, 3. , 2.8, 3.1, 3.4, 2.3, 2.2, 2.9, 2.9, 3.2, 3. , 2.9,\n",
            "       2.4, 3. , 2.8, 3.5, 2.9, 3.7, 3.2, 2.8, 3.3, 3.5, 3.7, 3.8, 3. ,\n",
            "       2.2, 3.1, 2.8, 2.6, 3.3, 2.5, 3.9, 3.2, 2.7, 2.8, 3. , 2.7, 3.6,\n",
            "       2.4, 3.8, 2.8], dtype=float32)>), ('petal_length', <tf.Tensor: shape=(120,), dtype=float32, numpy=\n",
            "array([1.5, 3.6, 5.1, 4.8, 1.4, 1.5, 6.1, 1.5, 4.5, 4.5, 3.3, 4. , 1.4,\n",
            "       1.3, 4.7, 5.1, 5.6, 5.5, 5.3, 5.8, 3.7, 5.2, 4.7, 4.5, 1.3, 6.7,\n",
            "       4.9, 6. , 1.7, 3.9, 1.5, 5.1, 5.9, 4.4, 1.6, 6. , 6.4, 1.4, 5.6,\n",
            "       5. , 1.6, 1.4, 4.5, 5.1, 6.1, 6.7, 5.5, 1.5, 1.6, 1.4, 1.7, 4.8,\n",
            "       5.6, 5.1, 5.5, 5.2, 5.6, 5.1, 1.4, 1.3, 4.4, 3. , 4.9, 4.1, 4.4,\n",
            "       5.8, 1.4, 1.2, 5.4, 3.5, 1. , 1.4, 1.2, 1.6, 6.9, 1.5, 4.9, 1.5,\n",
            "       4.5, 5.1, 6.6, 5.6, 1.6, 1.6, 1.3, 4.5, 6.3, 4.2, 1.3, 1.3, 4.6,\n",
            "       3.3, 5. , 4.1, 1.4, 4.7, 1.5, 5.7, 4.6, 5.7, 1.5, 1.5, 1.9, 4.2,\n",
            "       5. , 1.5, 4. , 4.4, 4.7, 3.9, 1.3, 4.8, 5.3, 4.8, 1.6, 4.2, 1.4,\n",
            "       3.8, 1.5, 6.1], dtype=float32)>), ('petal_width', <tf.Tensor: shape=(120,), dtype=float32, numpy=\n",
            "array([0.2, 1.3, 2.4, 1.4, 0.3, 0.1, 2.5, 0.4, 1.5, 1.5, 1. , 1.2, 0.2,\n",
            "       0.3, 1.2, 1.8, 2.4, 2.1, 2.3, 1.6, 1. , 2.3, 1.4, 1.7, 0.2, 2. ,\n",
            "       1.8, 1.8, 0.4, 1.4, 0.1, 1.6, 2.3, 1.3, 0.2, 2.5, 2. , 0.1, 2.1,\n",
            "       1.9, 0.2, 0.2, 1.5, 1.9, 2.3, 2.2, 1.8, 0.2, 0.6, 0.2, 0.3, 1.8,\n",
            "       1.4, 1.9, 1.8, 2. , 2.4, 2. , 0.2, 0.2, 1.4, 1.1, 1.5, 1. , 1.4,\n",
            "       2.2, 0.3, 0.2, 2.3, 1. , 0.2, 0.2, 0.2, 0.4, 2.3, 0.4, 1.8, 0.4,\n",
            "       1.3, 2.3, 2.1, 2.2, 0.2, 0.2, 0.3, 1.5, 1.8, 1.3, 0.2, 0.2, 1.3,\n",
            "       1. , 1.7, 1.3, 0.3, 1.4, 0.2, 2.3, 1.5, 2.1, 0.2, 0.2, 0.4, 1.2,\n",
            "       1.5, 0.1, 1.3, 1.2, 1.6, 1.1, 0.4, 1.8, 1.9, 1.8, 0.2, 1.3, 0.2,\n",
            "       1.1, 0.3, 1.9], dtype=float32)>)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX_5BfiGMdfO"
      },
      "source": [
        "la fonction pack_features_vector va rendre le dictionaire des features en une seule array liste de shape(120,4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jn5PqozMA07"
      },
      "source": [
        "def pack_features_vector(features, labels):\n",
        "  \"\"\"Pack the features into a single array.\"\"\"\n",
        "  features = tf.stack(list(features.values()), axis=1)\n",
        "  return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E69xvpjiMBrk",
        "outputId": "e8c3f4c7-144f-475c-b9f6-9a6e80acbdc8"
      },
      "source": [
        "train_dataset = train_dataset.map(pack_features_vector)\n",
        "features, labels = next(iter(train_dataset))\n",
        "print(labels[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 1 2 1 0 0 1 1], shape=(10,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFjoMhXzOfOk"
      },
      "source": [
        "# **Le choix du modèle**\n",
        "le modele va comporter **3 couche**,deux couches avec 10 noeud et une chouche de sortie avec trois noeud, et comme fonction d'activation j'ai choisi de travailler avec la donction **RELU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWSHDy2LOdsq"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(3)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3PR5A73PR-K"
      },
      "source": [
        "# **Training du modèle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-v4oT2lSUbc"
      },
      "source": [
        "## Définition de loss et gradiant "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO52sFBzPkxW"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfwlURCzPpyc",
        "outputId": "b75f72be-5b8d-45ef-bd18-22b8baafd11c"
      },
      "source": [
        "def loss(model, x, y, training):\n",
        " \n",
        "  y_ = model(x, training=training)\n",
        "\n",
        "  return loss_object(y_true=y, y_pred=y_)\n",
        "\n",
        "\n",
        "l = loss(model, features, labels, training=False)\n",
        "print(\"Loss test: {}\".format(l))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss test: 1.4662072658538818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlhUiVK7PwL0"
      },
      "source": [
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs, targets, training=True)\n",
        "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avVUqYGYP2QH"
      },
      "source": [
        "## Créer un optimiseur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yhg6lyvP7sn"
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS3sXZtZP_Au",
        "outputId": "2d1be963-13f4-4575-c037-a2e33b5c8477"
      },
      "source": [
        "loss_value, grads = grad(model, features, labels)\n",
        "\n",
        "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss_value.numpy()))\n",
        "\n",
        "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss(model, features, labels, training=True).numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step: 0, Initial Loss: 1.4662072658538818\n",
            "Step: 1,         Loss: 1.3233238458633423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n24y27vOS_xX"
      },
      "source": [
        "## Boucle d'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn8pVfTPTDBm",
        "outputId": "b738630c-e359-4ba2-c0a2-2721d85be304"
      },
      "source": [
        "\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 650\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "  \n",
        "  for x, y in train_dataset:\n",
        "    # Optimizer le modele\n",
        "    loss_value, grads = grad(model, x, y)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Track progress\n",
        "    epoch_loss_avg.update_state(loss_value)  # ajouter le loss courant\n",
        "    # comparaison entre le label prédictée et le label réel\n",
        "  \n",
        "    epoch_accuracy.update_state(y, model(x, training=True))\n",
        "\n",
        "  # End epoch\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "                                                                epoch_loss_avg.result(),\n",
        "                                                                epoch_accuracy.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: Loss: 1.323, Accuracy: 35.000%\n",
            "Epoch 050: Loss: 0.794, Accuracy: 69.167%\n",
            "Epoch 100: Loss: 0.701, Accuracy: 75.000%\n",
            "Epoch 150: Loss: 0.563, Accuracy: 86.667%\n",
            "Epoch 200: Loss: 0.461, Accuracy: 87.500%\n",
            "Epoch 250: Loss: 0.394, Accuracy: 90.000%\n",
            "Epoch 300: Loss: 0.346, Accuracy: 92.500%\n",
            "Epoch 350: Loss: 0.303, Accuracy: 95.000%\n",
            "Epoch 400: Loss: 0.265, Accuracy: 95.833%\n",
            "Epoch 450: Loss: 0.233, Accuracy: 96.667%\n",
            "Epoch 500: Loss: 0.209, Accuracy: 97.500%\n",
            "Epoch 550: Loss: 0.189, Accuracy: 97.500%\n",
            "Epoch 600: Loss: 0.173, Accuracy: 97.500%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZmgVQr3UVX7"
      },
      "source": [
        "# **Tester le modèle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkf-dLu8Usxt"
      },
      "source": [
        "Pour évaluer l'efficacité d'un modèle, les exemples utilisés sont différents que des exemples utilisés pour entraîner le modèle.\n",
        "\n",
        "La configuration de l'ensemble de Dataset test est similaire à la configuration de l'ensemble de Dataset entraînement. Téléchargez le fichier texte CSV et analysez ces valeurs, puis mélangez-le un peu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TvMF84pUHK_"
      },
      "source": [
        "test_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "test_fp = tf.keras.utils.get_file(fname=os.path.basename(test_url),\n",
        "                                  origin=test_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38drHbWcVGJz"
      },
      "source": [
        "test_dataset = tf.data.experimental.make_csv_dataset(\n",
        "    test_fp,\n",
        "    batch_size,\n",
        "    column_names=column_names,\n",
        "    label_name='species',\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "\n",
        "test_dataset = test_dataset.map(pack_features_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELitlzsTVKDp",
        "outputId": "f1d99031-3246-4599-c9f0-ff1a86944615"
      },
      "source": [
        "test_accuracy = tf.keras.metrics.Accuracy()\n",
        "\n",
        "for (x, y) in test_dataset:\n",
        "  \n",
        "  logits = model(x, training=False)\n",
        "  prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "  test_accuracy(prediction, y)\n",
        "\n",
        "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set accuracy: 93.333%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l-rY1EuVTbG"
      },
      "source": [
        "Visualiser les valeur prédictées par rapport aux valeurs originals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N86tQXNsVN5K",
        "outputId": "8c964449-0815-4c65-f3ff-5a60518d99ee"
      },
      "source": [
        "tf.stack([y,prediction],axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30, 2), dtype=int32, numpy=\n",
              "array([[1, 1],\n",
              "       [2, 2],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [2, 2],\n",
              "       [1, 1],\n",
              "       [2, 2],\n",
              "       [2, 2],\n",
              "       [0, 0],\n",
              "       [2, 2],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [2, 2],\n",
              "       [0, 0],\n",
              "       [1, 2],\n",
              "       [2, 2],\n",
              "       [1, 2],\n",
              "       [1, 1],\n",
              "       [1, 1],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [2, 2],\n",
              "       [1, 1]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxGVTrKaVo3d"
      },
      "source": [
        "on peut conclure que la majorité des valeurs prédictées sont correcte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFGVGcVsV9BE"
      },
      "source": [
        "# **Utilisation de modele**\n",
        "Apres avoir tester le modele , on peut dire qu'il bon,maintenat c'est le temps de l'utiliser pour predicter des nouvelles prédictions sur d'autres examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJgj6bB6WmBx",
        "outputId": "cfdce40b-436c-48b7-f6bb-eaab855e68b4"
      },
      "source": [
        "predict_dataset = tf.convert_to_tensor([\n",
        "    [4.8,3,1.4,0.3,],#setosa\n",
        "    [7,3.2,4.7,1.4],#versicolor\n",
        "    [6.3,2.5,5,1.9],#virginica\n",
        "    [5.9,3,5.1,1.8],#virginica\n",
        "    [5,3.3,1.4,0.2]#sesota\n",
        "])\n",
        "\n",
        "\n",
        "predictions = model(predict_dataset, training=False)\n",
        "\n",
        "for i, logits in enumerate(predictions):\n",
        "  class_idx = tf.argmax(logits).numpy()\n",
        "  p = tf.nn.softmax(logits)[class_idx]\n",
        "  name = class_names[class_idx]\n",
        "  print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example 0 prediction: Iris setosa (97.5%)\n",
            "Example 1 prediction: Iris versicolor (94.7%)\n",
            "Example 2 prediction: Iris virginica (76.9%)\n",
            "Example 3 prediction: Iris virginica (88.3%)\n",
            "Example 4 prediction: Iris setosa (98.7%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}